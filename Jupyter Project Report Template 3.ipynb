{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f9b735e2",
   "metadata": {},
   "source": [
    "# Title\n",
    "\n",
    "#### 1. Student name: Qingsheng Long\n",
    "#### 1. Student ID: 16387388\n",
    "\n",
    "#### 2. Student name:\n",
    "#### 2. Student ID: \n",
    "\n",
    "# Introduction\n",
    "\n",
    "Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exercitation ullamco laboris nisi ut aliquip ex ea commodo consequat. Duis aute irure dolor in reprehenderit in voluptate velit esse cillum dolore eu fugiat nulla pariatur. Excepteur sint occaecat cupidatat non proident, sunt in culpa qui officia deserunt mollit anim id est laborum\n",
    "\n",
    "\n",
    "## List the key steps you took to perform EDA\n",
    "\n",
    "1. 使用官方提供的interpolate_and_split.py文件对train_raw数据进行处理，得到新的训练数据集train_2.csv\n",
    "2. 使用merge_training_data.py对官方提供的train.csv和train_2.csv进行合并，并针对数据进行去重，得到更大的训练数据集train_merged.csv\n",
    "3. 把训练集进行分割为X_train和y_train两部分，用于训练模型\n",
    "4. 使用自定义函数def clean_input(X)对数据进行空值处理，主要采用bfill和ffill\n",
    "5. 使用K-flod对训练集交叉验证，并计算模型MSE\n",
    "\n",
    "\n",
    "## List and describe your kNN methodological design you used for experimental testing, benchmarking against a baseline, tuning, ensuring data leakage was not ocurring and how you effectively summarised and communicated all your results\n",
    "\n",
    "1. 本次分析/预测主要采用sklearn.neighbors包中的KNeighborsRegressor模型进行\n",
    "2. 在模型的预测中，训练集的-299~0列作为输入特征，1~300列作为输出标签\n",
    "3. 同时使用自定义函数find_best_parameter(max_k, metric_list, X_train, y_train, n_splits=5)对模型进行K-fold交叉验证，以求寻找到最佳的k-metric组合\n",
    "4. 在K-fold交叉验证过程中，针对k = 1~100, metric = ['euclidean', 'manhattan', 'cosine']共计300种参数组合进行验证\n",
    "5. 明确划分train.csv用于训练，test.csv用于预测，同时使用StandardScaler对数据进行归一化\n",
    "\n",
    "###  Best Kaggle score submission based on kNN\n",
    "\n",
    "- STATE HERE YOUR BEST SCORE AND WHERE YOU RANKED IN THE CLASS AT THE TIME OF SUBMISSION\n",
    "\n",
    "- EMBED THE SCREENSHOT OF YOUR BEST SUBMISSION SCORE FROM KAGGLE HERE\n",
    "\n",
    "\n",
    "## List all the predictive algorithms you used for the classification modelling component where you had the freedom to explore alternative methods. List here also your best Kaggle score and your position on the Kaggle leaderboard\n",
    "\n",
    "1. KNeighborsRegressor\n",
    "2. MLPRegressor\n",
    "3. ...\n",
    "4. ...\n",
    "\n",
    "\n",
    "\n",
    "## Analysis: list here all the remaining test design strategies you used, like k-fold CV, hyperparameter tuning, feature selection and feature engineering, discussion of your submission score results over time with resepct to model refinements and their effects\n",
    "\n",
    "1. K-Fold Cross-Validation：本实验中使用自定义函数find_best_parameter进行K-Fold Cross-Validation，在KNN模型中，评估不同的k值与metric对MSE的影响，从而选择出最佳的k-metric组合。在MLP模型中，则是对hyperparameters如hidden_layer_sizes，activations以及alphas进行测试，以求选择一个泛化能力良好的配置\n",
    "2. Hyperparameter Tuning：在KNN模型中，主要调整了k值(从1~100)和distance metrics(['euclidean', 'manhattan', 'cosine'])，并在K-Fold CV中检验模型MSE数值。而在MLP模型中，我采用了两中不同的策略，其中一种是：使用K-Fold CV找到最佳的参数组合，然后利用完整的训练集进行训练；另外一种则是不采用K-Fold CV，采用固定的参数搭配，利用train_test_split划分训练集来训练模型。\n",
    "3. Feature Engineering：因为训练数据中存在大量空值，而官方数据说明中表示\"values for columns -49..0 are present in all the rows\"，因此我分别尝试了采用[-299, 0]和]-49, 0]作为输入标签来训练模型。\n",
    "4. ...\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "## Bonus material\n",
    "\n",
    "### If you performed cluster analysis, decribe below what you did, how you did and what was the meaning and output:\n",
    "1. ...\n",
    "2. ...\n",
    "\n",
    "### If you conducted extensive extraction of additional features, list them below and explain how you extracted them and if each one was useful and how you determined this:\n",
    "\n",
    "1. ...\n",
    "2. ...\n",
    "3. ...\n",
    "4. ...\n",
    "\n",
    "\n",
    "## Did you submit your initial kaggle solution by May 1 and enter it into the Google Spreadsheet\n",
    "\n",
    "- YES\n",
    "\n",
    "## Have you submitted your reading log and integrated insights from your reading into this assignment\n",
    "\n",
    "- YES / NO\n",
    "- Discuss here how has your reading informed and helped guide your assignment 3? Which papers were particularly relevant and helpful and why? \n",
    "\n",
    "## Have you submitted your AI Use Statement\n",
    "\n",
    "- YES / NO\n",
    "\n",
    "  \n",
    "### Executive Summary\n",
    "\n",
    "Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exercitation ullamco laboris nisi ut aliquip ex ea commodo consequat. Duis aute irure dolor in reprehenderit in voluptate velit esse cillum dolore eu fugiat nulla pariatur. Excepteur sint occaecat cupidatat non proident, sunt in culpa qui officia deserunt mollit anim id est laborum\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "064291aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.model_selection import KFold\n",
    "from datetime import datetime\n",
    "from submission_record import prepare_submission"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "037049cf",
   "metadata": {},
   "source": [
    "# EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "683f9fe1-bf72-4dd5-9a72-3076f05c334e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_input(X):\n",
    "    return pd.DataFrame(X).interpolate(axis=1).bfill(axis=1).ffill(axis=1).to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a9962e62-7c38-4b78-9065-2be51b965de2",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = \"../data\"\n",
    "train_dataset = \"train.csv\"  # use the original dataset train.csv\n",
    "# train_dataset = \"train_raw.csv\"  # use the dataset train.csv which is built by 'interpolate_and_split.py'\n",
    "# train_dataset = \"train_merged.csv\"  # use the dataset which merge train.csv and train_2.csv\n",
    "train_df = pd.read_csv(os.path.join(DATA_DIR, train_dataset))\n",
    "test_df = pd.read_csv(os.path.join(DATA_DIR, \"test.csv\"))\n",
    "X_test = test_df.loc[:, [str(i) for i in range(-299, 1)]].to_numpy(dtype=np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "293acf43-2598-454a-8aa9-31d72be61db4",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train_df.loc[:, [str(i) for i in range(-299, 1)]].to_numpy(dtype=np.float32)\n",
    "y_train = train_df.loc[:, [str(i) for i in range(1, 301)]].to_numpy(dtype=np.float32)\n",
    "\n",
    "X_train2 = train_df.loc[:, [str(i) for i in range(1, 301)]].to_numpy(dtype=np.float32)\n",
    "y_train2 = train_df.loc[:, [f\"r_{r}_pos_{i}\" for r in range (1, 10) for i in range(1, 301)]].to_numpy(dtype=np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "86632c85",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = clean_input(X_train)\n",
    "y_train = clean_input(y_train)\n",
    "\n",
    "X_train2 = clean_input(X_train2)\n",
    "y_train2 = clean_input(y_train2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "20bd9f24",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "\n",
    "scaler2 = StandardScaler()\n",
    "X_train2 = scaler2.fit_transform(X_train2)\n",
    "\n",
    "X_test = clean_input(X_test)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3a6b1435-3df0-4939-8622-b3c81a3b7199",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7fd55821",
   "metadata": {},
   "source": [
    "# kNN Predictive Modelling\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "33324c7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_best_parameter(max_k, metric_list, X_train, y_train, n_splits=5):\n",
    "    result_list = []\n",
    "    kf = KFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
    "    print(\"Looking for the parameter combination with the smallest MSE...\")\n",
    "    for k in range(1, max_k + 1):\n",
    "        for metric in metric_list:\n",
    "            mse_fold = []\n",
    "            for train_index, val_index in kf.split(X_train):\n",
    "                X_tr, X_val = X_train[train_index], X_train[val_index]\n",
    "                y_tr, y_val = y_train[train_index], y_train[val_index]\n",
    "                model = KNeighborsRegressor(n_neighbors=k, weights='distance', metric=metric)\n",
    "                model.fit(X_tr, y_tr)\n",
    "                y_pred = model.predict(X_val)\n",
    "                mse = mean_squared_error(y_val, y_pred)\n",
    "                mse_fold.append(mse)\n",
    "\n",
    "            avg_mse = np.mean(mse_fold)\n",
    "            result_list.append((metric, k, avg_mse))\n",
    "\n",
    "    # Find the combination with the smallest MSE\n",
    "    best_result = min(result_list, key=lambda x: x[2])\n",
    "    print(f\"\\nBest Parameter: metric={best_result[0]}, k={best_result[1]}, MSE={best_result[2]:.5f}\")\n",
    "\n",
    "    return best_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75f6f9e9-0c76-48e4-84a8-e7723fa23f78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking for the parameter combination with the smallest MSE...\n",
      "\n",
      "Best Parameter: metric=euclidean, k=49, MSE=8.73558\n",
      "Looking for the parameter combination with the smallest MSE...\n"
     ]
    }
   ],
   "source": [
    "best_parameter1 = find_best_parameter(100, ['euclidean', 'manhattan', 'cosine'], X_train, y_train)\n",
    "best_parameter2 = find_best_parameter(100, ['euclidean', 'manhattan', 'cosine'], X_train2, y_train2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ee792c2-9493-4258-b13b-5a08cf90c6ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Training KNN Model...\")\n",
    "model1 = KNeighborsRegressor(n_neighbors=best_parameter1[1], weights='distance', metric=best_parameter1[0])\n",
    "model1.fit(X_train, y_train)\n",
    "\n",
    "model2 = KNeighborsRegressor(n_neighbors=best_parameter2[1], weights='distance', metric=best_parameter2[0])\n",
    "model2.fit(X_train2, y_train2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f32008fe-fadf-467a-9c21-e2cc26d150bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Predicting...\")\n",
    "y_pred = model1.predict(X_test)\n",
    "X_test2 = scaler2.transform(y_pred)\n",
    "y_pred_r_1_to_9 = model2.predict(X_test2)\n",
    "\n",
    "timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "prepare_submission.prepareSubmission(y_pred, \"../submission_record\", \"knn\", y_pred_r_1_to_9)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71af8ba3",
   "metadata": {},
   "source": [
    "# Modelling with alternative algorithms "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a699945-9063-46a6-a723-b872e1411670",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from submission_record import prepare_submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f40c7e58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split dataset for training and prediction\n",
    "tX, vX, ty, vy = train_test_split(X_train, y_train, test_size=0.2, random_state=42)\n",
    "tX2, vX2, ty2, vy2 = train_test_split(X_train2, y_train2, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "885af68c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Training MLP Model...\")\n",
    "model1 = MLPRegressor(\n",
    "    hidden_layer_sizes=(512, 256),\n",
    "    activation='tanh',\n",
    "    solver='adam',\n",
    "    learning_rate_init=0.001,\n",
    "    max_iter=2000,\n",
    "    random_state=42,\n",
    "    verbose=True,\n",
    "    alpha=1e-4\n",
    ")\n",
    "model1.fit(tX, ty)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4089f64e-5dde-4dd3-9700-e99655369aa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "model2 = MLPRegressor(\n",
    "    hidden_layer_sizes=(512, 256),\n",
    "    activation='tanh',\n",
    "    solver='adam',\n",
    "    learning_rate_init=0.001,\n",
    "    max_iter=2000,\n",
    "    random_state=42,\n",
    "    verbose=True,\n",
    "    alpha=1e-4\n",
    ")\n",
    "model2.fit(tX2, ty2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e57bea2c-653b-4090-9696-e6cb6573d22a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prediction\n",
    "y_pred = model1.predict(X_test)\n",
    "X_test2 = scaler2.transform(y_pred)\n",
    "y_pred_r_1_to_9 = model2.predict(X_test2)\n",
    "\n",
    "timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "prepare_submission.prepareSubmission(y_pred, \"../../submission_record\", \"mlp\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6335e9f6",
   "metadata": {},
   "source": [
    "# History and trend of Kaggle submission scores\n",
    "\n",
    "- try to plot your scores over time and discuss what experimental tweaks you performed at each step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64ece839",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b1a237e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "100e7002-1b86-4b9a-be1b-5fa699cee455",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8702304b",
   "metadata": {},
   "source": [
    "# Bonus Material\n",
    "\n",
    "\n",
    "### Cluster analysis\n",
    "\n",
    "\n",
    "### Description of how you extracted additional features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4f41dbf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "809b93c5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "46fcda90",
   "metadata": {},
   "source": [
    "# Conclusion \n",
    "\n",
    "\n",
    "Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exercitation ullamco laboris nisi ut aliquip ex ea commodo consequat. Duis aute irure dolor in reprehenderit in voluptate velit esse cillum dolore eu fugiat nulla pariatur. Excepteur sint occaecat cupidatat non proident, sunt in culpa qui officia deserunt mollit anim id est laborum\n",
    "\n",
    "## Key findings:\n",
    "\n",
    "1. Lorem ipsum dolor sit amet\n",
    "2. Lorem ipsum dolor sit amet\n",
    "3. Lorem ipsum dolor sit amet\n",
    "4. ...\n",
    "\n",
    "\n",
    "## Discuss what you learned the most fdrom this assignment\n",
    "\n",
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "291ea278",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b48bed72",
   "metadata": {},
   "source": [
    "## Bibliography (list of materials/code sources you used or refered to) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "beca57de",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "922d7bc5",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7855f828",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
